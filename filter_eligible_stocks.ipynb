{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d762f7",
   "metadata": {},
   "source": [
    "Ensures that the tickers are well visible, have finviz data that are readable and filters them by unaccetable levels of P/E, P/S and Debt/Eqt ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3759ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from finvizfinance.quote import finvizfinance\n",
    "\n",
    "# Set aesthetics\n",
    "sns.set(style='whitegrid', font_scale=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_col = 'final_return_1m_raw'\n",
    "pred_signal_threshold = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "# Replace with your prediction file path\n",
    "bounds = {\n",
    "    'Pred': (-0.02, 0.02),       # Adjust based on your prediction scale\n",
    "    'P/E': (5, 50),\n",
    "    'P/S': (1, 5),\n",
    "    'Debt/Eq': (0, 2),\n",
    "}\n",
    "\n",
    "higher_is_better = {\n",
    "    'P/E': False,\n",
    "    'P/S': False,\n",
    "    'Debt/Eq': False,\n",
    "    'Pred': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOAD PREDICTIONS ---\n",
    "pred_path = f\"data/inference/{pred_col}_inference_output.xlsx\"\n",
    "\n",
    "# --- LOAD PREDICTIONS ---\n",
    "df_pred = pd.read_excel(pred_path)  # use pd.read_csv(path) if it's a CSV\n",
    "\n",
    "# Rename columns for consistency\n",
    "df_pred.columns = [col.strip() for col in df_pred.columns]\n",
    "pred_col = [col for col in df_pred.columns if pred_col in col and \"score\" in col][0]\n",
    "\n",
    "# Keep only relevant columns\n",
    "df_pred = df_pred[['Ticker', 'Filing Date', pred_col]]\n",
    "df_pred = df_pred.rename(columns={pred_col: 'Pred'})\n",
    "\n",
    "# Convert date\n",
    "df_pred['Filing Date'] = pd.to_datetime(df_pred['Filing Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# Check\n",
    "print(\"‚úÖ Loaded predictions:\", df_pred.shape)\n",
    "display(df_pred.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finvizfinance.quote import finvizfinance\n",
    "\n",
    "def get_finviz_fundamentals(ticker):\n",
    "    \"\"\"\n",
    "    Fetches basic fundamental ratios from Finviz for a given ticker.\n",
    "    Returns a dictionary with P/E, P/S, and Debt/Eq if available.\n",
    "    \"\"\"\n",
    "    stock = finvizfinance(ticker)\n",
    "    info = stock.ticker_fundament()\n",
    "    \n",
    "    def parse_ratio(value):\n",
    "        try:\n",
    "            return float(value)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    return {\n",
    "        \"P/E\": parse_ratio(info.get(\"P/E\")),\n",
    "        \"P/S\": parse_ratio(info.get(\"P/S\")),\n",
    "        \"Debt/Eq\": parse_ratio(info.get(\"Debt/Eq\"))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27cc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# --- PREPARE TICKERS ---\n",
    "tickers = df_pred['Ticker'].unique()\n",
    "\n",
    "# --- FETCH FUNDAMENTALS ---\n",
    "fundamental_data = []\n",
    "\n",
    "for ticker in tqdm(tickers):\n",
    "    try:\n",
    "        finviz_data = get_finviz_fundamentals(ticker)\n",
    "        time.sleep(1)\n",
    "        finviz_data['Ticker'] = ticker\n",
    "        fundamental_data.append(finviz_data)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error for {ticker}: {e}\")\n",
    "\n",
    "df_fund = pd.DataFrame(fundamental_data)\n",
    "print(f\"‚úÖ Retrieved fundamentals for {len(df_fund)} tickers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MERGE ---\n",
    "df = df_pred[['Ticker', 'Pred']].merge(df_fund, on='Ticker', how='left')\n",
    "print(f\"‚úÖ Merged DataFrame: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ab421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=bounds.keys())\n",
    "\n",
    "# --- NORMALIZE FUNCTION ---\n",
    "def normalize(val, low, high, higher_better=True):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    norm = (val - low) / (high - low)\n",
    "    norm = np.clip(norm, 0, 1)\n",
    "    return norm if higher_better else 1 - norm\n",
    "\n",
    "# --- NORMALIZE EACH COLUMN ---\n",
    "df_norm = df.copy().drop_duplicates(subset=\"Ticker\", keep=\"first\")\n",
    "for col in bounds:\n",
    "    norm_col = col + ' (Norm)'\n",
    "    low, high = bounds[col]\n",
    "    df_norm[norm_col] = df[col].apply(normalize, args=(low, high, higher_is_better[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1955a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HEATMAP MATRIX (Normalized values) ---\n",
    "norm_cols = [col + ' (Norm)' for col in bounds]\n",
    "raw_cols = list(bounds.keys())\n",
    "\n",
    "# Ensure all necessary columns exist\n",
    "assert all(c in df_norm.columns for c in norm_cols), \"Missing normalized columns\"\n",
    "assert all(c in df_norm.columns for c in raw_cols), \"Missing raw columns\"\n",
    "\n",
    "# Construct matrices\n",
    "heatmap_values = df_norm.set_index('Ticker')[norm_cols].copy()\n",
    "heatmap_values.columns = raw_cols\n",
    "annotations = df_norm.set_index('Ticker')[raw_cols].round(3).astype(str)\n",
    "\n",
    "# --- PLOT HEATMAP ---\n",
    "plt.figure(figsize=(len(raw_cols) * 2.5, len(heatmap_values) * 0.4 + 3))\n",
    "sns.heatmap(\n",
    "    heatmap_values,\n",
    "    cmap=\"RdYlGn\",\n",
    "    annot=annotations,\n",
    "    fmt='',\n",
    "    linewidths=0.3,\n",
    "    linecolor='gray',\n",
    "    cbar=True,\n",
    "    annot_kws={\"size\": 8}\n",
    ")\n",
    "\n",
    "plt.title(\"üìä Normalized Financial Metrics (Colored) + Raw Values (Text)\", fontsize=14)\n",
    "plt.ylabel(\"Ticker\")\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_risk_pe(pe):\n",
    "    if pd.isna(pe): return np.nan\n",
    "    if 0 < pe <= 20: return 1\n",
    "    if 20 < pe <= 40: return 0.5\n",
    "    return 0\n",
    "\n",
    "def classify_risk_ps(ps):\n",
    "    if pd.isna(ps): return np.nan\n",
    "    if ps <= 4: return 1\n",
    "    if ps <= 10: return 0.5\n",
    "    return 0\n",
    "\n",
    "def classify_risk_de(de):\n",
    "    if pd.isna(de): return np.nan\n",
    "    if de <= 1: return 1\n",
    "    if de <= 2: return 0.5\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- COMPOSITE SCORE CONFIG ---\n",
    "pred_weight = 0.6\n",
    "risk_weight = 0.4\n",
    "\n",
    "# --- RISK SCORES ---\n",
    "df_norm['P/E Risk'] = df_norm['P/E'].apply(classify_risk_pe)\n",
    "df_norm['P/S Risk'] = df_norm['P/S'].apply(classify_risk_ps)\n",
    "df_norm['Debt/Eq Risk'] = df_norm['Debt/Eq'].apply(classify_risk_de)\n",
    "df_norm['Risk Score'] = df_norm[['P/E Risk', 'P/S Risk', 'Debt/Eq Risk']].mean(axis=1)\n",
    "\n",
    "# --- PREDICTION SCORE + BOOLEAN SIGNAL ---\n",
    "df_norm['Pred Score'] = (df_norm['Pred'] >= pred_signal_threshold).astype(int)\n",
    "\n",
    "# --- FILTER VALID ENTRIES ---\n",
    "df_valid = (\n",
    "    df_norm\n",
    "    .dropna(subset=['Pred Score', 'Risk Score'])\n",
    "    .drop_duplicates(subset='Ticker', keep='first')\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# --- COMPUTE COMPOSITE SCORE ---\n",
    "df_valid['Composite Score'] = (\n",
    "    df_valid['Pred Score'] * pred_weight +\n",
    "    df_valid['Risk Score'] * risk_weight\n",
    ")\n",
    "\n",
    "# --- RANKING ---\n",
    "df_valid['Rank'] = df_valid['Composite Score'].rank(method='max', ascending=False).astype(int)\n",
    "df_valid = df_valid.sort_values(by='Composite Score', ascending=False)\n",
    "\n",
    "# --- FINAL OUTPUT TABLE ---\n",
    "final_table = df_valid[['Ticker', 'Composite Score', 'Risk Score', 'Pred Score']].round(2)\n",
    "final_table = final_table.reset_index(drop=True)\n",
    "final_table.index += 1\n",
    "\n",
    "print(\"üèÜ Ranked Stocks by Prediction & Risk-Aware Composite Score:\")\n",
    "print(final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FILTER by Composite Score === 1 ---\n",
    "perfect_scores = df_valid[df_valid['Composite Score'] == 1].copy()\n",
    "\n",
    "# Optional: sort by any additional field (e.g., Pred Score)\n",
    "perfect_scores = perfect_scores.sort_values(by='Pred Score', ascending=False)\n",
    "\n",
    "# Display final filtered table\n",
    "print(\"üåü Stocks with Perfect Composite Score (1.0):\")\n",
    "print(perfect_scores[['Ticker', 'Composite Score', 'Pred Score', 'Risk Score']].reset_index(drop=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insideralgo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
